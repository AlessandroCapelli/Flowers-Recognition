{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Source Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0OfFtAWDfXm"
      },
      "source": [
        "# Project of Advanced Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxOgXMOVDfXt"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjjrv2wenury"
      },
      "source": [
        "pip install -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcwZHDfjDfXv"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "import PIL\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.backend\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tensorflow.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE5WblbCDfXw"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l9cxCJuDfXx"
      },
      "source": [
        "def get_image_names(tgz):\n",
        "    with tarfile.open(tgz) as file:\n",
        "        return [i.name for i in file.getmembers() if i.isfile()]\n",
        "\n",
        "def show_random_images(n=4, size=10, label=None):\n",
        "    if(label != None):\n",
        "        images = df[df['label'] == str(label)].sample(n=(n*n))\n",
        "    else:\n",
        "        images = df.sample(n=(n*n))\n",
        "        \n",
        "    plt.figure(figsize=(size, size))\n",
        "    for index, path in enumerate(images['id'].values):\n",
        "        plt.subplot(n, n, index+1)\n",
        "        plt.imshow(PIL.Image.open(DATA_PATH + 'images/' + path))\n",
        "        plt.title('Label: ' + str(images['label'].values[index]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def show_random_images_aug(aug, n=2, size=10):\n",
        "    x, y = aug.next()\n",
        "    \n",
        "    plt.figure(figsize=(size, size))\n",
        "    for i in range(0, (n*n)):\n",
        "        plt.subplot(n, n, i+1)\n",
        "        plt.imshow(x[i])\n",
        "        plt.title('Label: ' + str(np.where(y[i] == 1)[0][0]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(history.history['accuracy'], 'orange', label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], 'royalblue', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(history.history['precision'], 'orange', label='Training Precision')\n",
        "    plt.plot(history.history['val_precision'], 'royalblue', label='Validation Precision')\n",
        "    plt.title('Training and Validation Precision')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(history.history['recall'], 'orange', label='Training Recall')\n",
        "    plt.plot(history.history['val_recall'], 'royalblue', label='Validation Recall')\n",
        "    plt.title('Training and Validation Recall')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Recall')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(history.history['f1_score'], 'orange', label='Training F1-Score')\n",
        "    plt.plot(history.history['val_f1_score'], 'royalblue', label='Validation F1-Score')\n",
        "    plt.title('Training and Validation F1-Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1-Score')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(history.history['loss'], 'orange', label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], 'royalblue', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def true_positives(y_true, y_pred):\n",
        "    return tensorflow.keras.backend.sum(tensorflow.keras.backend.round(tensorflow.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    predicted_positives = tensorflow.keras.backend.sum(tensorflow.keras.backend.round(tensorflow.keras.backend.clip(y_pred, 0, 1)))\n",
        "\n",
        "    return true_positives(y_true, y_pred) / (predicted_positives + tensorflow.keras.backend.epsilon())\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    possible_positives = tensorflow.keras.backend.sum(tensorflow.keras.backend.round(tensorflow.keras.backend.clip(y_true, 0, 1)))\n",
        "\n",
        "    return true_positives(y_true, y_pred) / (possible_positives + tensorflow.keras.backend.epsilon())\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    possible_positives = tensorflow.keras.backend.sum(tensorflow.keras.backend.round(tensorflow.keras.backend.clip(y_true, 0, 1)))\n",
        "    predicted_positives = tensorflow.keras.backend.sum(tensorflow.keras.backend.round(tensorflow.keras.backend.clip(y_pred, 0, 1)))\n",
        "\n",
        "    return 2*(precision(y_true, y_pred)*recall(y_true, y_pred))/(precision(y_true, y_pred)+recall(y_true, y_pred)+tensorflow.keras.backend.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgdgpW-oDfXy"
      },
      "source": [
        "## Configuration parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WptElZuQEbWs",
        "outputId": "958735b8-3660-4c1a-d392-8dc31bc629c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXhIxp-tDfX0"
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/data/' #  './data/'\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "TEST_RATIO = 0.3\n",
        "VALIDATION_RATIO = 0.2\n",
        "NUM_CLASSES = 102\n",
        "IMG_SIZE = 250\n",
        "IMG_CHANNELS = 3\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "VERBOSE = 1\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 5\n",
        "\n",
        "CHECKPOINT = ModelCheckpoint((DATA_PATH + 'model.hdf5'), monitor=['val_accuracy'], verbose=VERBOSE, mode='max')\n",
        "EARLYSTOP = EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D_pQ291DfX0"
      },
      "source": [
        "## Base models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XPBeUxQDfX0",
        "outputId": "40cf19c4-1312-45d0-e298-9e8b91d36026"
      },
      "source": [
        "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "model_vgg.trainable = False\n",
        "\n",
        "model_vgg.summary()\n",
        "\n",
        "model_xception = Xception(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "model_xception.trainable = False\n",
        "\n",
        "model_xception.summary()\n",
        "\n",
        "model_resnet = ResNet50V2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "model_resnet.trainable = False\n",
        "\n",
        "model_resnet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 250, 250, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 124, 124, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 124, 124, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 124, 124, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 122, 122, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 122, 122, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 122, 122, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 122, 122, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 122, 122, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 122, 122, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 122, 122, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 122, 122, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 61, 61, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 61, 61, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 61, 61, 128)  512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 61, 61, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 61, 61, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 61, 61, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 61, 61, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 61, 61, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 61, 61, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 61, 61, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 31, 31, 256)  32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 31, 31, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 31, 31, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 31, 31, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 31, 31, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 31, 31, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 31, 31, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 31, 31, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 31, 31, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 31, 31, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 728)  186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 728)  2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,861,480\n",
            "__________________________________________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 250, 250, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 256, 256, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 125, 125, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 127, 127, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 63, 63, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 63, 63, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 63, 63, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 63, 63, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 63, 63, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 63, 63, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 65, 65, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 63, 63, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 63, 63, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 63, 63, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 63, 63, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 63, 63, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 63, 63, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 63, 63, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 63, 63, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 63, 63, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 63, 63, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 63, 63, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 65, 65, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 63, 63, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 63, 63, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 63, 63, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 63, 63, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 63, 63, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 63, 63, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 63, 63, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 63, 63, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 63, 63, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 63, 63, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 65, 65, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of9vKuJYDfX3"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3zJszVJDfX3"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['id'] = sorted(get_image_names(DATA_PATH + 'images.tgz'))\n",
        "df['label'] = scipy.io.loadmat(DATA_PATH + 'labels.mat')['labels'][0] - 1\n",
        "df['label'] = df['label'].astype('str')\n",
        "\n",
        "tarfile.open(DATA_PATH + 'images.tgz').extractall(DATA_PATH + 'images/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M9eZEidDfX4"
      },
      "source": [
        "print('Size of dataset:')\n",
        "print(df.count())\n",
        "\n",
        "print('\\nList of images:')\n",
        "print(os.listdir(DATA_PATH + 'images/jpg')[:10])\n",
        "\n",
        "print('\\nDataframe:')\n",
        "print(df.head(10))\n",
        "\n",
        "print('\\nNumber of classes:')\n",
        "print(df['label'].nunique())\n",
        "\n",
        "print('\\nImages for each class:')\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "print('\\nSample images:')\n",
        "show_random_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8_KHGSbDfX6"
      },
      "source": [
        "## Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7n9X16vDfX6"
      },
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(\n",
        "    df['id'], \n",
        "    df['label'], \n",
        "    test_size=TEST_RATIO, \n",
        "    random_state=SEED, \n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "train_X, validation_X, train_y, validation_y = train_test_split(\n",
        "    train_X, \n",
        "    train_y, \n",
        "    test_size=(VALIDATION_RATIO/(1-TEST_RATIO)), \n",
        "    random_state=SEED,\n",
        "    stratify=train_y\n",
        ")\n",
        "\n",
        "train = pd.DataFrame(train_X)\n",
        "train['label'] = train_y\n",
        "\n",
        "validation = pd.DataFrame(validation_X)\n",
        "validation['label'] = validation_y\n",
        "\n",
        "test = pd.DataFrame(test_X)\n",
        "test['label'] = test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOaUF4oVDfX7"
      },
      "source": [
        "print('Size of train set:')\n",
        "print(train.shape)\n",
        "\n",
        "print('\\nDataframe of the train set:')\n",
        "print(train.head(10))\n",
        "\n",
        "print('\\nImages for each class of the train set:')\n",
        "print(train['label'].value_counts())\n",
        "\n",
        "print('\\nSize of validation set:')\n",
        "print(validation.shape)\n",
        "\n",
        "print('\\nDataframe of the validation set:')\n",
        "print(validation.head(10))\n",
        "\n",
        "print('\\nImages for each class of the validation set:')\n",
        "print(validation['label'].value_counts())\n",
        "\n",
        "print('\\nSize of test set:')\n",
        "print(test.shape)\n",
        "\n",
        "print('\\nDataframe of the test set:')\n",
        "print(test.head(10))\n",
        "\n",
        "print('\\nImages for each class of the test set:')\n",
        "print(test['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7jzcvZ3DfX7"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LULYp5bNDfX7",
        "scrolled": false
      },
      "source": [
        "pd.DataFrame(df['label'].value_counts(sort=True)).plot(kind='barh', figsize=(10, 20), color='royalblue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eh__ouoDfX8"
      },
      "source": [
        "pd.DataFrame(train['label'].value_counts(sort=True)).plot(kind='barh', figsize=(10, 20), color='royalblue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYuHxLzaDfX9"
      },
      "source": [
        "pd.DataFrame(validation['label'].value_counts(sort=True)).plot(kind='barh', figsize=(10, 20), color='royalblue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eule5C0yDfX9"
      },
      "source": [
        "pd.DataFrame(test['label'].value_counts(sort=True)).plot(kind='barh', figsize=(10, 20), color='royalblue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9niX7G_DfX-"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9g5XrBQDfX-",
        "outputId": "0f4ecbfd-b725-4c37-ad6d-5d3aa69ad5c1"
      },
      "source": [
        "train_aug_datagen = ImageDataGenerator(\n",
        "    rotation_range=45, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1, \n",
        "    brightness_range=[0.5, 1.5], \n",
        "    shear_range=0.15, \n",
        "    zoom_range=[0.75, 1.25], \n",
        "    fill_mode=\"nearest\", \n",
        "    horizontal_flip=True, \n",
        "    rescale=1./255\n",
        ")\n",
        "train_aug = train_aug_datagen.flow_from_dataframe(\n",
        "    dataframe=train, \n",
        "    directory=(DATA_PATH + 'images/'), \n",
        "    x_col='id', \n",
        "    y_col='label', \n",
        "    target_size=(IMG_SIZE, IMG_SIZE), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    class_mode='categorical', \n",
        "    shuffle=True, \n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "validation_aug_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "validation_aug = validation_aug_datagen.flow_from_dataframe(\n",
        "    dataframe=validation, \n",
        "    directory=(DATA_PATH + 'images/'), \n",
        "    x_col='id', \n",
        "    y_col='label', \n",
        "    target_size=(IMG_SIZE, IMG_SIZE), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    class_mode='categorical', \n",
        "    shuffle=True, \n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "test_aug_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "test_aug = test_aug_datagen.flow_from_dataframe(\n",
        "    dataframe=test, \n",
        "    directory=(DATA_PATH + 'images/'), \n",
        "    x_col='id', \n",
        "    y_col='label', \n",
        "    target_size=(IMG_SIZE, IMG_SIZE), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    class_mode='categorical', \n",
        "    shuffle=True, \n",
        "    seed=SEED\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4094 validated image filenames belonging to 102 classes.\n",
            "Found 1638 validated image filenames belonging to 102 classes.\n",
            "Found 2457 validated image filenames belonging to 102 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJypoYbADfX-",
        "scrolled": false
      },
      "source": [
        "print('Sample augmented images of the train set:')\n",
        "show_random_images_aug(aug=train_aug)\n",
        "\n",
        "print('Sample augmented images of the validation set:')\n",
        "show_random_images_aug(aug=validation_aug)\n",
        "\n",
        "print('Sample augmented images of the test set:')\n",
        "show_random_images_aug(aug=test_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjcuvaqaDfX_"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogdjWGUEDfX_"
      },
      "source": [
        "tensorflow.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D5NCVS-8J45"
      },
      "source": [
        "### Model creation for manual tuning of hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkDW8jfdDfYA",
        "scrolled": true
      },
      "source": [
        "def create_model(BASE_MODEL, LR, DROPOUT_RATE, NUM_UNITS, ACTIVATION, REGULARIZER=None):\n",
        "    BASE_MODEL_TEMP = BASE_MODEL\n",
        "    BASE_MODEL_TEMP.trainable = True\n",
        "\n",
        "    # fine_tune_at = int(round(len(BASE_MODEL_TEMP.layers)))\n",
        "    # for layer in BASE_MODEL_TEMP.layers[:fine_tune_at]:\n",
        "    #     layer.trainable = False\n",
        "    \n",
        "    # for layer in BASE_MODEL_TEMP.layers: \n",
        "    #     layer.build(layer.input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(BASE_MODEL_TEMP)\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(NUM_UNITS, activation=ACTIVATION, kernel_regularizer=REGULARIZER))\n",
        "    model.add(Dropout(DROPOUT_RATE))\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=Adam(lr=LR), \n",
        "        metrics=[precision, recall, f1_score, AUC(), 'accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_LYg48w8e5x"
      },
      "source": [
        "### Model creation for automatic tuning of hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkjVT1t38iBS"
      },
      "source": [
        "def build_model(hp):\n",
        "    BASE_MODEL_TEMP = model_resnet\n",
        "    BASE_MODEL_TEMP.trainable = True\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(BASE_MODEL_TEMP)\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(hp.Int('NUM_UNITS', 128, 1024, step=128, default=256), activation=hp.Choice(f'ACTIVATION', ['elu', 'relu']), kernel_regularizer=l2(3e-1)))\n",
        "    model.add(Dropout(hp.Float(f'DROPOUT_RATE', 0.1, 0.7, step=0.1, default=0.5)))\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=Adam(lr=hp.Choice(f\"LR\", [1e-5, 2e-5, 5e-5, 5e-6])), \n",
        "        metrics=[precision, recall, f1_score, AUC(), 'accuracy']\n",
        "    )\n",
        "  \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNp7EooBDfYA"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPYcaC0x7JSH"
      },
      "source": [
        "### Naive approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejsEJO1wDfYA"
      },
      "source": [
        "PARAMS = {\n",
        "    'BASE_MODEL': [{'MODEL': model_resnet, 'NAME': 'RESNET50V2'}], # [{'MODEL': model_vgg, 'NAME': 'VGG16'}, {'MODEL':  model_xception, 'NAME': 'XCEPTION'}, {'MODEL': model_resnet, 'NAME': 'RESNET50V2'}],\n",
        "    'LR': [2e-5], # [1e-3, 1e-4],\n",
        "    'EPOCHS': [50],\n",
        "    'DROPOUT_RATE': [0.45], # [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "    'NUM_UNITS': [256], # [128, 256, 512],\n",
        "    'ACTIVATION': ['elu'], # ['elu', 'relu'],\n",
        "    'REGULARIZER': [{'REGULARIZER': l2(3e-1), 'NAME': 'L2(0.3)'}] # [{'REGULARIZER': l1(5e-3), 'NAME': 'L1(0.005)'}, {'REGULARIZER': l2(1e-2), 'NAME': 'L2(0.01)'}, {'REGULARIZER': l1(5e-4), 'NAME': 'L1(0.0005)'}, {'REGULARIZER': l2(1e-3), 'NAME': 'L2(0.001)'}]\n",
        "}\n",
        "\n",
        "with open(DATA_PATH + 'results.csv', mode='w') as results:\n",
        "    results_writer = csv.writer(results, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    results_writer.writerow(['EPOCHS', 'BATCH SIZE', 'BASE MODEL', 'DROPOUT RATE', 'LR', 'NUM UNITS', 'ACTIVATION', 'REGULARIZER', 'LOSS', 'ACCURACY', 'PRECISION', 'RECALL', 'F1-SCORE', 'VALIDATION LOSS', 'VALIDATION ACCURACY', 'VALIDATION PRECISION', 'VALIDATION RECALL', 'VALIDATION F1-SCORE'])\n",
        "\n",
        "for EPOCHS in PARAMS['EPOCHS']:\n",
        "    for BASE_MODEL in PARAMS['BASE_MODEL']:\n",
        "        for DROPOUT_RATE in PARAMS['DROPOUT_RATE']:\n",
        "            for REGULARIZER in PARAMS['REGULARIZER']:\n",
        "                for LR in PARAMS['LR']:\n",
        "                    for NUM_UNITS in PARAMS['NUM_UNITS']:\n",
        "                        for ACTIVATION in PARAMS['ACTIVATION']:\n",
        "                            with open(DATA_PATH + 'results.csv', mode='a') as results:\n",
        "                                results_writer = csv.writer(results, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "                                model = create_model(BASE_MODEL['MODEL'], LR, DROPOUT_RATE, NUM_UNITS, ACTIVATION, REGULARIZER['REGULARIZER'])\n",
        "                                model.summary()\n",
        "\n",
        "                                history = model.fit(\n",
        "                                    train_aug,\n",
        "                                    validation_data=validation_aug,\n",
        "                                    epochs=EPOCHS,\n",
        "                                    callbacks=[CHECKPOINT, EARLYSTOP],\n",
        "                                    verbose=VERBOSE\n",
        "                                )\n",
        "\n",
        "                                print('[INFO] Model:\\n\\tBase model: ', BASE_MODEL['NAME'], '\\n\\tEpochs: ', EPOCHS, '\\n\\tLearning rate: ', LR, '\\n\\tBatch size: ', BATCH_SIZE, '\\n\\tNum units: ', NUM_UNITS, '\\n\\tActivation: ', ACTIVATION, '\\n\\tDropout rate: ', DROPOUT_RATE, '\\n\\tRegularizer: ', REGULARIZER['NAME'])\n",
        "                                print('[WEIGHTS] Model:\\n\\tSum of the weights of first dense layer: ', sum(sum(abs(model.layers[3].get_weights()[0]))), '\\n\\tSum of the biases of first dense layer: ', sum(abs(model.layers[3].get_weights()[1])), '\\n\\tSum of the weights of second dense layer: ', sum(sum(abs(model.layers[5].get_weights()[0]))), '\\n\\tSum of the biases of second dense layer: ', sum(abs(model.layers[5].get_weights()[1])))\n",
        "                                print('[TRAINING] Model:\\n\\tTrain loss: ', history.history['loss'][-1], '\\n\\tTrain accuracy: ', history.history['accuracy'][-1], '\\n\\tTrain precision: ', history.history['precision'][-1], '\\n\\tTrain recall: ', history.history['recall'][-1], '\\n\\tTrain f1-score: ', history.history['f1_score'][-1])\n",
        "                                print('[VALIDATING] Model:\\n\\tValidation loss: ', history.history['val_loss'][-1], '\\n\\tValidation accuracy: ', history.history['val_accuracy'][-1], '\\n\\tValidation precision: ', history.history['val_precision'][-1], '\\n\\tValidation recall: ', history.history['val_recall'][-1], '\\n\\tValidation f1-score: ', history.history['val_f1_score'][-1])\n",
        "                                plot_history(history)\n",
        "\n",
        "                                results_writer.writerow([EPOCHS, BATCH_SIZE, BASE_MODEL['NAME'], DROPOUT_RATE, LR, NUM_UNITS, ACTIVATION, REGULARIZER['NAME'], history.history['loss'][-1], history.history['accuracy'][-1], history.history['precision'][-1], history.history['recall'][-1], history.history['f1_score'][-1], history.history['val_loss'][-1], history.history['val_accuracy'][-1], history.history['val_precision'][-1], history.history['val_recall'][-1], history.history['val_f1_score'][-1]])\n",
        "                                model.save(DATA_PATH + 'model_' + str(EPOCHS) + '_' + str(BATCH_SIZE) + '_' + BASE_MODEL['NAME'] + '_' + str(DROPOUT_RATE) + '_' + str(LR) + '_' + str(NUM_UNITS) + '_' + ACTIVATION + '_' + REGULARIZER['NAME'] + '.hdf5')                        \n",
        "                                \n",
        "                                tensorflow.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ViSOHf7UoE"
      },
      "source": [
        "### Structured approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzuNFlcs7YUY",
        "outputId": "0a0f97b4-9366-4012-8c8b-edf1ee754cb1"
      },
      "source": [
        "EPOCHS = 10\n",
        "MAX_TRIALS = 32\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=MAX_TRIALS,\n",
        "    directory=DATA_PATH,\n",
        "    project_name='FlowersRecognition'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    train_aug, \n",
        "    validation_data=validation_aug, \n",
        "    epochs=EPOCHS, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True)],\n",
        "    verbose=VERBOSE\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "NUM_UNITS         |128               |896               \n",
            "ACTIVATION        |elu               |elu               \n",
            "DROPOUT_RATE      |0.2               |0.3               \n",
            "LR                |2e-05             |1e-05             \n",
            "\n",
            "Epoch 1/10\n",
            "128/128 [==============================] - 122s 915ms/step - loss: 74.2511 - precision: 0.5292 - recall: 0.1556 - f1_score: 0.2264 - auc: 0.7650 - accuracy: 0.2682 - val_loss: 54.2783 - val_precision: 0.9806 - val_recall: 0.7760 - val_f1_score: 0.8647 - val_auc: 0.9942 - val_accuracy: 0.8736\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 116s 908ms/step - loss: 49.7632 - precision: 0.9820 - recall: 0.7858 - f1_score: 0.8701 - auc: 0.9978 - accuracy: 0.8868 - val_loss: 37.7808 - val_precision: 0.9753 - val_recall: 0.9012 - val_f1_score: 0.9362 - val_auc: 0.9969 - val_accuracy: 0.9365\n",
            "Epoch 3/10\n",
            "128/128 [==============================] - 117s 909ms/step - loss: 34.6289 - precision: 0.9900 - recall: 0.9207 - f1_score: 0.9536 - auc: 0.9986 - accuracy: 0.9596 - val_loss: 26.5380 - val_precision: 0.9742 - val_recall: 0.9351 - val_f1_score: 0.9539 - val_auc: 0.9977 - val_accuracy: 0.9493\n",
            "Epoch 4/10\n",
            "128/128 [==============================] - 116s 908ms/step - loss: 24.3555 - precision: 0.9917 - recall: 0.9516 - f1_score: 0.9709 - auc: 0.9997 - accuracy: 0.9750 - val_loss: 18.9053 - val_precision: 0.9836 - val_recall: 0.9453 - val_f1_score: 0.9638 - val_auc: 0.9974 - val_accuracy: 0.9585\n",
            "Epoch 5/10\n",
            "128/128 [==============================] - 116s 906ms/step - loss: 17.3849 - precision: 0.9930 - recall: 0.9697 - f1_score: 0.9810 - auc: 0.9999 - accuracy: 0.9840 - val_loss: 13.7669 - val_precision: 0.9723 - val_recall: 0.9373 - val_f1_score: 0.9541 - val_auc: 0.9968 - val_accuracy: 0.9481\n",
            "Epoch 6/10\n",
            "128/128 [==============================] - 116s 905ms/step - loss: 12.6772 - precision: 0.9917 - recall: 0.9739 - f1_score: 0.9826 - auc: 0.9997 - accuracy: 0.9853 - val_loss: 10.2338 - val_precision: 0.9756 - val_recall: 0.9453 - val_f1_score: 0.9599 - val_auc: 0.9962 - val_accuracy: 0.9512\n",
            "Epoch 7/10\n",
            "128/128 [==============================] - 115s 900ms/step - loss: 9.4535 - precision: 0.9942 - recall: 0.9748 - f1_score: 0.9842 - auc: 0.9996 - accuracy: 0.9889 - val_loss: 7.7684 - val_precision: 0.9766 - val_recall: 0.9519 - val_f1_score: 0.9639 - val_auc: 0.9971 - val_accuracy: 0.9603\n",
            "Epoch 8/10\n",
            "123/128 [===========================>..] - ETA: 4s - loss: 7.2022 - precision: 0.9967 - recall: 0.9860 - f1_score: 0.9912 - auc: 0.9998 - accuracy: 0.9916"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEnxBziK7p3x",
        "outputId": "cf4b87c2-d99f-45b3-8cb2-aba2ea490f92"
      },
      "source": [
        "model = tuner.get_best_models()[0]\n",
        "model.save(DATA_PATH + 'model.hdf5')\n",
        "model = tensorflow.keras.models.load_model(DATA_PATH + 'model.hdf5', custom_objects={'precision': precision, 'recall': recall, 'f1_score': f1_score})\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 8, 8, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 2048)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 896)               29361024  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 896)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 102)               91494     \n",
            "=================================================================\n",
            "Total params: 53,017,318\n",
            "Trainable params: 52,971,878\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmuZ4Y58DfYC"
      },
      "source": [
        "## Model testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLXiZl1DDfYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38df98a-453b-4fc7-9254-f009f5851223"
      },
      "source": [
        "score = model.evaluate(test_aug, verbose=VERBOSE)\n",
        "print('[TESTING] Model:\\n\\tTest loss: ', score[0], '\\n\\tTest accuracy: ', score[5], '\\n\\tTest precision: ', score[1], '\\n\\tTest recall: ', score[2], '\\n\\tTest f1-score: ', score[3], '\\n\\tTest auc: ', score[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77/77 [==============================] - 989s 13s/step - loss: 47.8312 - precision: 0.9695 - recall: 0.9391 - f1_score: 0.9538 - auc: 0.9945 - accuracy: 0.9524\n",
            "[TESTING] Model:\n",
            "\tTest loss:  47.831172943115234 \n",
            "\tTest accuracy:  0.9523809552192688 \n",
            "\tTest precision:  0.9695348143577576 \n",
            "\tTest recall:  0.9391233921051025 \n",
            "\tTest f1-score:  0.9537907242774963 \n",
            "\tTest auc:  0.9945472478866577\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}